{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution role is arn:aws:iam::251344623468:role/service-role/AmazonSageMaker-ExecutionRole-20191017T203175\n",
      "Success - the MySageMakerInstance is in the ap-northeast-1.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sagemaker import get_execution_role\n",
    "import boto3, sys, os\n",
    "import sagemaker\n",
    "\n",
    "# S3 prefix\n",
    "bucket = 'sagemaker-getting-start-test'\n",
    "prefix = 'sagemaker/sklearn-randomforest'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Execution role is \" + role)\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (IllegalLocationConstraintException) when calling the CreateBucket operation: The unspecified location constraint is incompatible for the region specific endpoint this request was sent to.\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if my_region == 'ap-northeast-1':\n",
    "        s3.create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket, CreateBucketConfiguration={'LocationConstraint': my_region})\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload csv train data to S3\n",
    "WORK_DIRECTORY = 'data'\n",
    "train_input = sagemaker_session.upload_data(\"{}/train_tweets.csv\".format(WORK_DIRECTORY), bucket=bucket, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-03 09:45:10 Starting - Starting the training job...\n",
      "2020-06-03 09:45:12 Starting - Launching requested ML instances.........\n",
      "2020-06-03 09:46:53 Starting - Preparing the instances for training...\n",
      "2020-06-03 09:47:31 Downloading - Downloading input data...\n",
      "2020-06-03 09:47:43 Training - Downloading the training image...\n",
      "2020-06-03 09:48:25 Training - Training image download completed. Training in progress.\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mObtained 12055 features in dataset\u001b[0m\n",
      "\u001b[34mX shape: (59440, 12055)\u001b[0m\n",
      "\u001b[34my shape: (59440,)\u001b[0m\n",
      "\n",
      "2020-06-03 09:50:13 Uploading - Uploading generated training model\n",
      "2020-06-03 09:50:13 Completed - Training job completed\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "Training seconds: 162\n",
      "Billable seconds: 162\n"
     ]
    }
   ],
   "source": [
    "# train data and save a model\n",
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "container_name = 'sklearn-rf-container'\n",
    "image_full = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, container_name)\n",
    "\n",
    "clf = sagemaker.estimator.Estimator(image_full, role, 1, 'ml.c4.2xlarge', \n",
    "                                    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "\n",
    "# training tweet data with RandomForestClassifier in scikit-learn container\n",
    "clf.fit(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = clf.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: (2, 12055)\n"
     ]
    }
   ],
   "source": [
    "# load test payload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"{}/payload_tweet.csv\".format(WORK_DIRECTORY), header=None)\n",
    "print(\"test_data: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(test_data.values).decode('utf-8')\n",
    "predictions_array = np.fromstring(predictions, sep=' ') # and turn the prediction into an array\n",
    "print(\"Predicted values: {}\".format(predictions_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
